1.31
   @13 数据集  V1.0_10K 未清洗
              V1.1_10K  清洗1加去模糊
   @13  ct  V1.0_10K
   
1.30
   @BeGAN 需要见过该人物，不然无法得到结果  单个文件夹处理太麻烦  费时间
   @CycleGAN 两个 类两个类训练 麻烦
1.29 
   @19 试试AM-softmax
   @13 试试20K的情况
1.28
   @19 flip softmax   4K时梯度爆炸  降低学习率  loss较低
      LFW: 28K  0.85116   84.8000+1.3740
           30K  0.85133   84.9000+1.3748
           
   @19 flip- one(0.1-10-5) 
      LFW: 28K  0.9853   98.4333+0.8667
           30K  0.9855   98.5167+0.7544
   
1.27
   @19 t0  norm->fc6->scale->softmax  
   @19 t1  norm->fc6->scale->softmax
           norm->ct-one(0.1-10-5)
   drop_out=0.2 的影响
1.26
   @13     no_faceScrub 
   MS_20000       BLUFR 98.25%  92.23%   77.40%
   MS_20000nv1.1  BLUFR 98.07%  90.67%   75.95%
1.25
  1.
1.24
  1.读论文BLUFR
  2.cycle GAN
  3.Unbluring_
   50:@19  t0  ct        MS_unbluring (k-means) 1.24
           LFW:    0.991   98.9500+0.3500
           BLUFR:  94.49%  78.46%  61.95%
            
      @19  to norm center_one(0.1,10,1) 1.25 ×
      
      @19  t1  center_one(0.1,10,1)  1.24  nan ×
  4.找出LFW 中错误剪裁的
1.23
  1.跑了一遍BLUFR，准确率应该会提升吧
  2.使用SSD跑了人体检测
  
1.22
  1.@13 去模糊  threshold=40   一共解压了2W个类
    @13 使用K-Means 聚类， 参数： choose the big group as center  #balance_threhold=3   //
                                dist_to_cent> 0.4342   vg_dist>0.35  remain_num>=40
1.20
  1.实验  @13数据增广  色彩变换
1.17 
  1.cosine_loss : normal l2,scale=5   loss-weight=0.01
  2.实验 cosine_loss weight_decay: 10?
1.16
  1.实验 ：batch_norm
          @16 t2 batch_norm 的位置 convolution->bn->relu 之后 0.001 Nan   end 1.16
  
  2.实验：LightCNN    --灰度图像
          @19 MS_50K(>50张图片）  image_size lr=0.001
                      不降就加ct试试
  3.视频抽帧 --
1.15 
  1.修改one_loss  #只更新C  不更新X
         @16 t0 beta=1    margin=10 top_n =5  ->nan 5K iter
         @16 t1 beta=1    margin=10 top_n =1    Loss_one=1039.19  后降  
                          23000次被断过128->256   0.9875   98.6333+0.6574
         //drop out=0.2                 
         @16 t1  ct      batch =256 √     
            LFW:  28K  0.991    99.0667+0.3350
                  30K  0.991    98.9667+0.4643
            BLUFR:28K  96.36%   85.22%  68.72%
                  30K  96.46%   85.35%  68.53%        
                        
         @16 t0 beta=0.1  margin=10 top_n =1   batch =256  √   
            LFW:  28K  99.03   98.8833+0.5220
                  30K  99.05   98.9500+0.6238
            BLUFR:28K  96.25%  85.27%  70.03%     
                  30K: 96.21%  84.99%  69.22%
                  
         @16 t0 beta=0.1  margin=10 top_n =3   batch =256     √
            LFW:  28K  0.9913    99.0333+0.4069
                  30K  0.99116   99.0500+0.4153   
            BLUFR:28K  96.48%  85.48%  68.35%
                  30K  96.49%  85.50%  68.15%
         
         @16 t2 beta=0.1    margin=10 top_n =5   batch =256 √ 
            LFW:  28k  0.991     99.0333+0.3930
                  30K  0.99116   99.1000+0.4096
            BLUFR:28k  96.52%  85.68%  69.71% 
                  30K  96.53%  85.71%  69.42%
         
         @16 t1  beta=0.1    margin=10  top_n =10 √
            LFW:  28k  0.99016   98.8667+0.4876
                  30K  0.9903    98.9333+0.4359
            BLUFR:28k  96.61%  87.14%  71.17%
                  30K  96.58%  86.98%  70.80% 
             
         @16 t1 beta=0.01    margin=10 top_n =1   batch =256  √
             LFW:  28K  0.99116   99.0500+0.3655
                   30K  0.99116   99.1+0.3266
             BLUFR:28K  96.34%  85.31%  66.50%      
                   30K  96.36%  85.30%  66.72%
                   
         @16 t0   beta=0.01    margin=10 top_n =3  batch =256  √
             LFW:  28k   0.99183  99.1667+0.3162  
                   30K   0.99183  99.1667+0.3162  
            BLUFR: 28k   96.43%  85.51%  67.49%    
                   30K   96.45%  85.71%  68.58%
         
         @16 t2 beta=1    margin=10 top_n =1   batch =256   √
             LFW:  28K 0.9903   98.9000+0.4607
                   30K 0.9906   99.0167+0.3452
             BLUFR:28K  96.06%  83.85%  65.64%
                   30K  96.12%  84.20%  66.55%
         @16 t0 beta=1    margin=10 top_n =3   batch =256    √
             LFW:  28K  0.9905  98.9833+0.6167
                   30K  0.9905  99.0167+0.6167   
             BLUFR:28K  96.14%   85.72%  69.89%     
                   30K  96.13%   65.68%  69.74%
                   
        
            
         @16 t2  beta=0.1    margin=10  top_n =20   √
            LFW: 28K             
                 30K  0.990666   98.9833+0.5747
                 
            BLUFR:28K  
                  30K  96.95%  88.57%  72.92%
                  
          @16 t0  beta=0.1    margin=15  top_n =5    √
            LFW: 28K   0.991      99.0833+0.4958
                 30K   0.99116    99.1+0.4422
            BLUFR:28K  
                  30K  96.68%  86.73%  70.60%
                  
         @16 t0  beta=0.1    margin=15  top_n =10  √
           LFW: 28K             
                30K  0.99016     98.95+0.4947   
                
           BLUFR:28K  
                  30K 96.74%  87.28%  71.40%  √
         
         @16 t1  beta=0.1    margin=15  top_n =20
            LFW: 28K             
                 30K  0.99133       99.1167+0.4475
                 
            BLUFR:28K  
                  30K 96.87%  88.29%  73.25%
                  
                  
         
          beta =0.1         
          top_n 越大越好
          margin 越大越好
          
          
          @16 t0  beta=0.1    margin=20  top_n =20
            LFW: 28K             
                 30K  
                 
            BLUFR:28K  
                  30K 
                  
          @16 t0  beta=0.1    margin=50  top_n =100
            LFW: 28K             
                 30K  
                 
            BLUFR:28K  
                  30K
                  
           
         以上都使用了dropout……0.2
         @16 t2   beta=0.01    margin=10 top_n =5
         
         
         @16 t1   ct-no drop-out   √
             LFW:  28K             
                  30K    0.9905      98.9667+0.4269
             BLUFR: 28K  
                   30K   95.19%   80.42%  61.46%
        
         
         
          
  
  2.BUG：  进去后除以一个数后为0,可能是因为在一个循环里面除以的。除以了多次！
  3.测试 batch_size的影响
1.13
  @13 avg_loss
         beta=0.001   0.989   98.8167±0.5795
         beta=0.005   99.1    99.0500±0.4349
         beta=0.01    98.967  98.9000+0.4485
  
  实验1： 测试图片数 目前50  25,50,75,100,125过拟合？
         @19 t1 25   lfw    0.9768   97.4500+1.1644       #128 8K 12K 14K
         @19 t0 50   lfw    0.9868   98.5833+0.6203       #256 8K 12K 14K
         @19 t0 75   lfw    0.9902   98.9000+0.4726       #256 16K 24K 28K
         @19 t1 100  lfw    0.9902   98.9333+0.4899       #256 16K 24K 28K
         @ 125？
 
         
  实验2： 对于cosine_loss  
         1.batch——norm
         2.norm   
         3.norm   
         4.drop_out  
              @16 cosine_loss 加 dropout=0.5(不收敛）  0.2 不收敛
         
1.12
  实验：
  Resnet 将图片换成224*224 原网络有降  softmax=3.0  速度慢   有fc5 
  @16 lfw 0.9765  97.5500+0.7267
1.11
  1. 如何调整参数 http://rishy.github.io/ml/2017/01/05/how-to-train-your-dnn/
                 http://blog.csdn.net/sinat_26917383/article/details/54232791
                 http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html
     CNN和全连接层 为什么固定大小 http://blog.csdn.net/dugudaibo/article/details/78452893   局部连接层
     
  2. cosine loss 过拟合
  3. overlap 10000出结果
  4.训练自己的模型 非图片 http://blog.csdn.net/shadow_guo/article/details/50382446
1.10
  1.DenseNet 修改完成 XXXXX
    @19 Resnet-50  
  2. 弄懂resnet http://blog.csdn.net/wspba/article/details/56019373    
  
                https://www.jianshu.com/p/1c7668f1dc25    -------------改进Resnet模型
         inception 
         convolution层 http://blog.csdn.net/zhubenfulovepoem/article/details/29583429 
  3.
  3.multi-scale ?
1.9
  1.python多进程  http://blog.csdn.net/jinlong_xu/article/details/67649206
  2.@16 center_cosine_loss  loss_weight=0.1    0.0008没有效果
1.8
 1.vnc  
 #启动 vncserver #返回一个端口号
 #关闭 vncserver -kill :端口号
 # win7启动vnc viewer 软件 输入vnc server address ip：端口号    pass：hqh123456
 # 保存
 
 Q:显示灰色界面 
 A: 修改/home/qionghua.he/.vnc/xstartup 
# Uncomment the following two lines for normal desktop:
# unset SESSION_MANAGER
# exec /etc/X11/xinit/xinitrc
[ -x /etc/vnc/xstartup ] && exec /etc/vnc/xstartup
[ -r $HOME/.Xresources ] && xrdb $HOME/.Xresources
xsetroot -solid grey
vncconfig -iconic &
#x-terminal-emulator -geometry 80x24+10+10 -ls -title "$VNCDESKTOP Desktop" &
#x-window-manager &

export XKL_XMODMAP_DISABLE=1
unset SESSION_MANAGER
unset DBUS_SESSION_BUS_ADDRESS

gnome-session&
gnome-panel&
gnome-settings-daemon&
gnome-terminal&
metacity&
nautilus&


 2.DCGAN:  https://github.com/carpedm20/DCGAN-tensorflow
 3.清理模糊图片 MS_10000  ！！！！！！！！！！
 
1.6
  1.@19 MS_10000n (no overlap all of 3)
  2.
1.4
  1.@13 run 增广MS_10000n（no overlap_LFW&YTF&Facescrub）
  
1.3
  1.YTF并没有排除 ！！！
  2.MS20000n 提取LFW特征  0.9955  99.5167±0.2522
             提取FaceScrube/megaFace1M特征 
  3.图像变换 
     --安装TensorFlow https://www.tensorflow.org/install/install_linux#InstallingVirtualenv  
     (P:libcudnn.so.6: cannot open shared object file             
      A:pip install tensorflow-gpu==1.2)
     --HQH\code\DataAug_2.py
