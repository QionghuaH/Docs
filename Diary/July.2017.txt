#Record waht I learned in July.2017
Day:2  
    1.>read the paper 'NormFace-L2 Hypersphere Embedding for Face Verification' 
    2.>The implementation of this paper  #https://github.com/happynear/NormFace
Day:3
    1.>how to implement the L2_norm  #http://freesouls.github.io/2015/08/30/caffe-implement-l2-normlization-layer/
    2.>set the fixed Scale_param: by set the lr_mult: 0  #https://stackoverflow.com/questions/37410996/scale-layer-in-caffe
    3.> 以minist为例，如果一次送进来一张图片，因为上一层inner_product层输出10个节点，则bottom ： num = 1, channels = 10, height = 1, width = 1;
        #http://lib.csdn.net/snippet/deeplearning/48428
Day:5
    1.>论文:A Proximity-Aware Hierarchical Clustering of Faces  定义了新的相似距离
    2.>
Day:7
    1.>用100个类resnet101+center_loss 有收敛
    2.>看懂了center_loss，InnerProdcuts的caffe代码   #http://blog.csdn.net/seven_first/article/details/47378697#6caffecopy-函数  
    3.>了解了caffe调用过程     #https://buptldy.github.io/2016/10/09/2016-10-09-Caffe_Code/
Day:8
    1.>transform th 'dateset_60000' imageTxt to lmdb file(with size 112*112)   
    2.>183 resnet101—l2-ct-10000(w/o dropout)
    3.>100 class try to test the model(ct /withou ct /dropout=0.5)
    
Day:12    
    1.> this.blob[0]->mutable_gpu_diff()   this.blob[0]->mutable_gpu_data() #caffe 数据结构
    2.> this.blob[0] this.blob[1] means weight & bias
    3.>C++中的结构 struct MyStruct  {  int member_a;  };    
      @MyStruct s; s.member_a = 1;  
      @MyStruct * ps; ps->member_a = 1; (*ps).member_a = 1; 
Day:13
   1.>blob.shape=n×c×h×w shape.size=4 num_axis=4(0,1,2,3) count=n×c×h×w
   2.> solver->net->layer->sgd_slover->net.update()   http://www.cnblogs.com/573177885qq/p/6079280.html

    
 
