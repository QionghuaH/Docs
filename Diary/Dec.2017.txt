12.21 
  1.minist 可视化 ？
12.20 
  1.L=|ci|-E(ci)/N  maybe help   minist 0.005  0.01√  0.05√  0.1
  2.L=cosine(xi,ci) 
  3. see how good on MS_celeb （overlaped）
12.19
  1. center_loss_me  |ci|>margin (5->25)
  2. MS20000u 实验：lr=0.01 center_loss=0.1 
  3. normalization? try @13 scale=40  需要的话 可以变成cuda类型的 串行
12.18
  1.MS20000u不降的 u表示未清理
  原因：？调整
     1.降低学习率 lr=0.01
     2.增加center_loss的比例 0.016  失败！
  2.center_loss_me 不降的原因？ 10000*10000 迭代次数太大
12.17
  1.MS20000n @19
  2.get_overlap.py(为MS创建字典，然后提取LFW测试name 和MS中的匹配 如果有就保存到文本LFW_MS_overlap.txt )
  3.以前训练的MS10000 与LFW 重合 595个
                   与facescrub 重合 25个
  4.以前训练的MS20000 与LFW 重合 848个
                   与facescrub 重合 35个   
12.16
  MS10000 megaface 0.608225
  MS12000 megaface 0.915969
  
12.13
  1.center_loss_me后面不收敛了
  2.使用MS_20000模型提取MegaFace1M_Aligned的特征
  3.extractFeature_megaface.py  batch_size=1变成batch_size=100
12.12
  1.仿真center_invariant_loss成功   收敛慢
  2.LOG(INFO) << "center_invariant_loss :loss=: " << loss; 打印某个变量
  3.弄明白了contrastive loss的代码Li,j=y(xi-xj)^2+(1-y)(margin-(xi-xj)^2) 和反向传到 根据y的值xi，xj求导
  4.修改center_loss 
    L=LS+λLcme
    Lcme=Lc+βLme
    Lme=1/2*β*Εmax(|M-|ci-cj|^2|,0)
    △Ci=-1/(N_-1)*β*E(ci-cj) j=0……n
12.6
  1.修改center_loss_12.6
    L=Ls+λLc+1/4*βLcd
    Lcd=Ε||ci-cj|^2-M|^2 (j=0-N_&& j!=i)
    △Ci= ..+1/(N_-1)*β*Ε||ci-cj|^2-M|*(ci-cj)
  2.@19 β=0.05  margin=5
  
  3.整理minist数据集LMDB caffe根目录下
   sh ./data/mnist/get_mnist.sh
   sh ./examples/mnist/create_mnist.sh
   
12.5
  1.MS_20000u不收敛，center loss很小，约等于0，，softmax 9.87 
    原因：可能内部差异太大了，所以中心不明确
    
12.3
  1.@13 MS_20000u
  2.MS_10000u 提取特征
  3. LFW MS_10000u  98.6±0.62
  4. YTF MS_10000u  94.9±0.6549

    

